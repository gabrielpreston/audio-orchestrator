# discord-voice-lab environment template
#
# This sample shows the new split between shared defaults and service-specific
# configuration files. Copy each section into the matching path before running
# `make dev-*` or `make run`.

########################
# ./.env.common       #
########################
LOG_LEVEL=info
LOG_JSON=true

# Logging sampling and rate limiting
LOG_SAMPLE_VAD_N=50
LOG_SAMPLE_UNKNOWN_USER_N=100
LOG_RATE_LIMIT_PACKET_WARN_S=10

# OpenTelemetry Configuration
OTEL_ENABLED=true
OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
OTEL_TRACES_SAMPLER=parentbased_traceratio
OTEL_TRACES_SAMPLER_ARG=1.0

#######################################
# ./services/discord/.env.service     #
#######################################
DISCORD_BOT_TOKEN=changeme
DISCORD_GUILD_ID=000000000000000000
DISCORD_VOICE_CHANNEL_ID=000000000000000000
DISCORD_AUTO_JOIN=false
DISCORD_INTENTS=guilds,guild_voice_states
DISCORD_VOICE_CONNECT_TIMEOUT=15
DISCORD_VOICE_CONNECT_ATTEMPTS=3
DISCORD_VOICE_RECONNECT_BASE_DELAY=5
DISCORD_VOICE_RECONNECT_MAX_DELAY=60
AUDIO_ALLOWLIST=
AUDIO_SILENCE_TIMEOUT=0.75
AUDIO_MAX_SEGMENT_DURATION=15
AUDIO_MIN_SEGMENT_DURATION=0.3
AUDIO_AGGREGATION_WINDOW=1.5
AUDIO_SAMPLE_RATE=48000
AUDIO_VAD_SAMPLE_RATE=16000
AUDIO_VAD_FRAME_MS=30
AUDIO_VAD_AGGRESSIVENESS=1
STT_BASE_URL=http://stt:9000
STT_TIMEOUT=45
STT_MAX_RETRIES=3
STT_FORCED_LANGUAGE=en
STT_VAD_FILTER=false
WAKE_MODEL_PATHS=
WAKE_PHRASES=hey atlas,ok atlas,atlas,hey assistant,ok assistant
ORCHESTRATOR_WAKE_PHRASES=
WAKE_THRESHOLD=0.3
WAKE_SAMPLE_RATE=16000
METRICS_PORT=
WAVEFORM_DEBUG_DIR=
ORCHESTRATOR_URL=http://orchestrator:8000

###################################
# ./services/stt/.env.service     #
###################################
FW_MODEL=medium.en
FW_DEVICE=cpu
FW_COMPUTE_TYPE=int8
FW_ENABLE_ENHANCEMENT=false

#######################################
# ./services/flan/.env.service     #
#######################################
PORT=8100
FLAN_T5_MODEL_SIZE=google/flan-t5-large
TRANSFORMERS_CACHE=/app/models
ENABLE_MODEL_CACHING=true
MAX_SEQUENCE_LENGTH=512
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=50
REPETITION_PENALTY=1.1

#######################################
# ./services/orchestrator/.env.service #
#######################################
PORT=8200
LLM_PRIMARY_URL=http://flan:8100
GUARDRAILS_URL=http://guardrails:9300
LANGCHAIN_VERBOSE=true
MAX_TOKENS=512
TEMPERATURE=0.7
ENABLE_TOOL_CALLING=true
ENABLE_GUARDRAILS=true

########################
# ./.env.common       #
########################
LOG_LEVEL=info
LOG_JSON=true

# Logging sampling and rate limiting
# Sample high-frequency events to reduce log volume in production.
LOG_SAMPLE_VAD_N=50
LOG_SAMPLE_UNKNOWN_USER_N=100
LOG_RATE_LIMIT_PACKET_WARN_S=10

# OpenTelemetry Configuration
OTEL_ENABLED=true
OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
OTEL_TRACES_SAMPLER=parentbased_traceratio
OTEL_TRACES_SAMPLER_ARG=1.0

########################
# ./.env.docker       #
########################
PUID=1000
PGID=1000
TZ=Etc/UTC

#######################################
# ./services/bark/.env.service     #
#######################################
PORT=7100
BARK_USE_SMALL_MODELS=false
DEFAULT_VOICE=v2/en_speaker_1
MAX_TEXT_LENGTH=1000
SAMPLE_RATE=22050

#######################################
# ./services/audio/.env.service #
#######################################
PORT=9100
ENABLE_ENHANCEMENT=true
ENABLE_VAD=true
ENABLE_HIGH_PASS=true
ENABLE_VOLUME_NORMALIZATION=true
ENABLE_NOISE_REDUCTION=true
VAD_AGGRESSIVENESS=1
HIGH_PASS_CUTOFF=80.0
TARGET_RMS=0.1
MAX_CONCURRENT_REQUESTS=10
FRAME_PROCESSING_TIMEOUT_MS=20
ENHANCEMENT_TIMEOUT_MS=50
METRICGAN_MODEL_SOURCE=speechbrain/metricgan-plus-voicebank
METRICGAN_MODEL_SAVEDIR=pretrained_models/metricgan-plus
PORT=7000
TTS_MODEL_PATH=/app/models/piper/en_US-amy-medium.onnx
TTS_MODEL_CONFIG_PATH=/app/models/piper/en_US-amy-medium.onnx.json
TTS_DEFAULT_VOICE=
TTS_MAX_TEXT_LENGTH=1000
TTS_MAX_CONCURRENCY=4
TTS_RATE_LIMIT_PER_MINUTE=60
TTS_AUTH_TOKEN=changeme
TTS_LENGTH_SCALE=1.0
TTS_NOISE_SCALE=0.667
TTS_NOISE_W=0.8

# Discord warm-up and logging sampling
DISCORD_WARMUP_AUDIO=true
LOG_SAMPLE_SEGMENT_READY_RATE=
LOG_SAMPLE_SEGMENT_READY_N=

# STT warm-up
STT_WARMUP=true

# Discord service modes
DISCORD_FULL_BOT=false
DISCORD_HTTP_MODE=false
DISCORD_MCP_MODE=false

# Orchestrator client timeout (used by Discord client)
ORCH_TIMEOUT=30

# LLM generation defaults (overridable per-request)
LLM_MAX_TOKENS=128
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
LLM_TOP_K=40
LLM_REPEAT_PENALTY=1.1
# LLAMA_THREADS can also be set in services/llm/app.py env
