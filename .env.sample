# discord-voice-lab example environment
# Copy this to .env.local (gitignored) and replace placeholders before running locally.

# -----------------------------
# Core bot / discovery
# -----------------------------
# Required: Discord bot token (keep secret)
DISCORD_BOT_TOKEN="YOUR_DISCORD_BOT_TOKEN"
# Optional: auto-join targets (use with GUILD_ID)
GUILD_ID=""
VOICE_CHANNEL_ID=""
# Optional comma-separated allowlist of Discord user IDs (processor will ignore other users when set)
ALLOWED_USER_IDS=""
# Comma-separated event names that should always produce detailed dumps
DETAILED_EVENTS=""

# MCP / service registry (optional)
MCP_URL="http://mcp:8000"
MCP_NAME="bot"
BOT_EXTERNAL_URL="http://bot:8080"

# -----------------------------
# Logging / debug
# -----------------------------
LOG_LEVEL=info
PAYLOAD_MAX_BYTES=1024
REDACT_LARGE_BYTES=1024

# -----------------------------
# STT (Whisper) / FastWhisper service
# -----------------------------
# URL where decoded PCM/WAV is POSTed. When unset, processor drops audio.
WHISPER_URL="http://stt:9000/asr"
# If truthy (true/1/yes), add task=translate to the whisper request
WHISPER_TRANSLATE=false
# Query params and STT options
STT_BEAM_SIZE=7
STT_LANGUAGE="en"
STT_WORD_TIMESTAMPS=true
TEXT_FORWARD_URL=""
# Timeout used when calling WHISPER_URL (ms)
WHISPER_TIMEOUT_MS=30000

# Fast-whisper service local settings (used by services/stt)
FW_MODEL=small
FW_DEVICE=cpu
FW_COMPUTE_TYPE=""

# -----------------------------
# Audio accumulation / VAD / flush tuning
# -----------------------------
# Values are examples; tune them for your environment
MIN_FLUSH_MS=1750
FLUSH_TIMEOUT_MS=1200
MAX_ACCUM_MS=20000
VAD_RMS_THRESHOLD=110
FLUSH_ON_MIN=false
SILENCE_TIMEOUT_MS=1000
TRANSCRIPT_AGG_MS=2400
WAKE_PHRASE_WINDOW_S=3
WAKE_PHRASES="hey assistant, ok assistant"

# -----------------------------
# Orchestrator / LLM (chat completions)
# -----------------------------
# OpenAI-compatible endpoint where aggregated transcripts are POSTed (optional)
ORCHESTRATOR_URL="http://orch:8000/v1/chat/completions"
ORCH_AUTH_TOKEN="changeme"
ORCH_TIMEOUT_MS=30000

# OpenAI-style client variables (used by orchestrator / docs)
OPENAI_BASE_URL=""
OPENAI_API_KEY=""
OPENAI_MODEL="gpt-5"
OPENAI_FALLBACK_MODEL="local"
GPT5_ENABLED=true

# Optional local LLM binary/model (services/llm)
LLAMA_BIN="/usr/local/bin/llama"
LLAMA_MODEL_PATH="/app/models/llama2-7b.gguf"
PORT=8000

# LLM guardrails (examples)
LLM_MAX_TOKENS=4000
LLM_MAX_COST_PER_MINUTE_USD=1.00
LLM_USE_FUNCTION_CALLS=true
LLM_DEFAULT_TEMPERATURE=0.2
LLM_LOG_PROMPTS=false
LLM_METRICS_EXPORT=false

# -----------------------------
# TTS / playback
# -----------------------------
TTS_PROVIDER=""
TTS_URL="http://tts:9000/synthesize"
TTS_AUTH_TOKEN="changeme"

# -----------------------------
# Save audio / sidecars
# -----------------------------
# Enable writing decoded WAVs and JSON sidecars
SAVE_AUDIO_ENABLED=false
# Container-local directory written by the bot (container path)
SAVE_AUDIO_DIR_CONTAINER="/app/wavs"
# Host path you may mount into the container (for compose setups)
SAVE_AUDIO_DIR_HOST="./.wavs"
# Optional explicit combined dir used by code when set
SAVE_AUDIO_DIR=""
SAVE_AUDIO_RETENTION_HOURS=72
SAVE_AUDIO_CLEAN_INTERVAL_MIN=10
SAVE_AUDIO_MAX_FILES=0
SIDECAR_LOCKING=false

# -----------------------------
# Misc / developer examples
# -----------------------------
# Example: size of audio chunks read before transcription (if used)
RECORD_SECONDS=8