FW_MODEL=medium.en
FW_DEVICE=cuda
FW_COMPUTE_TYPE=float16
FW_ENABLE_ENHANCEMENT=false

# Model download and cache configuration
FORCE_MODEL_DOWNLOAD_WHISPER_MODEL=false

# STT performance optimizations
# Note: torch.compile() is NOT applicable - faster-whisper uses CTranslate2 backend
# Pre-warming to ensure models are ready before serving traffic
STT_ENABLE_PREWARM=true

# Result caching for identical audio requests (significant speedup for repeated audio)
STT_ENABLE_CACHE=true
STT_CACHE_MAX_ENTRIES=200
STT_CACHE_MAX_SIZE_MB=1000
