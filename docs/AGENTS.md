# ðŸŽ™ Voice-Orchestrated AI System

## System Guidelines and Expectations for Participating Agents

**Version:** 1.0

**Author:** Gabriel Preston

**Last Updated:** 2025-10-08

---

## 1. System Purpose

This system enables **natural, voice-driven interaction** between humans and AI agents inside Discord.
It provides a shared orchestration layer that connects:

* **Speech interfaces** (voice capture, wake-word detection, transcription, TTS)
* **Reasoning engines** (LLMs, planners, context managers)
* **Operational tools** (Git, file management, APIs, automation tasks)

The goal is to create an ecosystem where a user can speak naturally to the system, and the agent network cooperatively interprets intent, performs tasks, and communicates resultsâ€”entirely through structured, interoperable actions.

---

## 2. Core Roles and Services

| Service                  | Language                | Function                    | Description                                                                                                                 |
| ------------------------ | ----------------------- | --------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| **Discord Voice Bot**    | Python                      | Voice Gateway               | Connects to Discord voice channels, captures user audio, detects wake phrases, and plays synthesized audio replies.         |
| **Speech-to-Text (STT)** | Python (faster-whisper) | Transcription Engine        | Converts incoming voice segments into text in near-real time for the orchestrator.                                          |
| **LLM Orchestrator**     | Python (llama.cpp)      | Reasoning and Planning Core | Interprets transcribed input, determines intent, plans multi-step actions, and routes them to available tools or services.  |
| **Additional Capability Servers**   | Mixed                   | Tool Execution              | Implement discrete skills such as file management, Git operations, HTTP/API calls, or text-to-speech synthesis.             |
| **MCP Fabric**           | Protocol Layer          | Coordination Standard       | The standardized communication layer used by all services to describe, discover, and invoke tools safely and declaratively. |

---

## 3. What the System Does

1. **Listens** for user speech in Discord voice channels.
2. **Detects** a configured wake phrase locally (low-latency KWS).
3. **Transcribes** the following speech segment via faster-whisper.
4. **Understands and plans** using llama.cpp.
5. **Executes actions** by invoking available MCP tools (Git, FS, TTS, etc.).
6. **Responds** in natural voice through the Discord bot using generated audio.

The result is a **continuous conversational control loop** where the AI listens, thinks, acts, and speaksâ€”without manual input or switching modalities.

---

## 4. Architectural Overview

```text
ðŸŽ¤ User speaks
   â†“
[Python Discord Bot]
   - Captures audio
   - Detects wake phrase
   - Streams to STT
   â†“
[Python faster-whisper]
   - Transcribes speech â†’ text
   â†“
[Python LLM Orchestrator (llama.cpp)]
   - Interprets intent
   - Queries tool registry
   - Invokes MCP tools (Github.com, Cursor.com, Monday.com)
   â†“
[Additional Capability Servers]
   - Perform other actions (FS, TTS)
   â†“
[Python Discord Bot]
   - Receives response
   - Plays audio reply
```

Each arrow represents a **structured, schema-validated interface**, independent of implementation language.

---

## 5. Responsibilities by Layer

### Discord Bot (Python)

* Capture and normalize per-user audio streams.
* Detect wake phrases before invoking transcription.
* Forward speech segments to STT service.
* Play audio output generated by the orchestrator or TTS server.
* Expose its own actions (e.g., `discord.speak`, `discord.join`, `discord.message`) as discoverable MCP tools.

### STT Service (faster-whisper)

* Provide low-latency, streaming transcription via MCP.
* Return text and timestamps in structured JSON.
* Support multiple concurrent sessions with minimal GPU contention.

### LLM Orchestrator (llama.cpp)

* Receive transcription text and conversation context.
* Reason about user intent and required actions.
* Discover and call available MCP tools (Github.com, Cursor.com, Monday.com).
* Aggregate results and generate structured responses (including speech prompts for TTS).

### Additional Capability Servers

* Implement focused domains (e.g., TTS, file ops).
* Register tools with the orchestrator through the MCP manifest.
* Validate inputs, perform deterministic actions, and return machine-readable outputs.

### MCP Layer

* Standardizes tool definition and invocation.
* Handles service discovery, authentication, and schema validation.
* Provides an auditable contract between reasoning agents and operational tools.
* All components must expose their capabilities and metadata via MCP.

---

## 6. Communication and Configuration

### Transport

* Default transport between services is **WebSocket (wss://)**.
* Each service maintains a persistent, authenticated connection.
* Local development may use **stdio** transport for simplicity.

### Configuration

* All integrations are defined declaratively in a **manifest file** (`mcp.json`).
* The manifest describes:

  * Available MCP servers
  * Tool namespaces and expected schemas
  * Auth modes (e.g., `mtls`, `bearer`)
  * Policies (timeouts, rate limits, access scopes)
  * Environment overlays (`dev`, `stage`, `prod`)

### Discovery

* On startup, the orchestrator loads the manifest, connects to all declared MCP servers, and caches their available tool metadata for planning.
* Tool discovery is refreshed periodically or upon receiving registry updates.

---

## 7. Data and Control Flow Expectations

### Input Stream

* Discord bot decodes Opus packets to PCM and segments by voice activity.
* Wake phrase triggers speech capture.
* Captured segment is streamed to STT service via MCP call.

### Processing

* STT returns partial and final transcriptions incrementally.
* Orchestrator consumes transcripts and builds a structured instruction graph.
* The orchestrator uses the MCP client to invoke one or more tools in sequence or parallel.

### Output

* Tool responses (JSON) return to orchestrator.
* Orchestrator composes final response text.
* TTS server synthesizes speech.
* Discord bot plays the resulting audio clip in channel.

---

## 8. Security and Operational Policy

* **Authentication:** All MCP connections must use verified credentials (mTLS or short-lived tokens).
* **Authorization:** Each tool invocation must check policy constraints (user, channel, or context).
* **Isolation:** Run each capability server in a sandboxed environment with least-privilege permissions.
* **Auditing:** Log all `ListTools`, `CallTool`, and `InvokeResult` events with timestamps and correlation IDs.
* **Privacy:** Audio data is transient; raw voice packets are discarded after transcription unless explicitly persisted for debugging.

---

## 9. Performance Targets

| Metric                        | Target                     |
| ----------------------------- | -------------------------- |
| Wake-phrase detection latency | < 200 ms                   |
| STT transcription start       | < 300 ms from speech onset |
| End-to-response latency       | < 2 s (for short queries)  |
| Tool invocation throughput    | â‰¥ 100 concurrent calls     |
| TTS playback start delay      | < 500 ms after text ready  |

Performance tuning priorities: **KWS â†’ STT â†’ Orchestration â†’ TTS** in that order.

---

## 10. Observability & Health

* Every service must expose:

  * **Health endpoint** (`/health` or MCP equivalent)
  * **Metrics** (Prometheus or structured JSON)
  * **Structured logs** (JSON with correlation IDs)
* Orchestrator aggregates distributed traces for full request visibility.
* Failure of one service should degrade gracefully without blocking others.

---

## 11. Extensibility Guidelines

* New tools are registered by adding entries to the manifest (`mcp.json`).
* Tool names follow a hierarchical namespace (e.g., `git.commit`, `discord.message`).
* Schemas define clear, minimal inputs and outputs.
* Each new server must pass the orchestratorâ€™s **discovery and validation tests** before being used in production.
* Existing services can be swapped or upgraded independently as long as schemas remain stable.

---

## 12. Agent Expectations

If you are an **AI Agent** participating in this system:

1. **Read and understand the manifest (`mcp.json`)** at initialization to know which tools and services exist.
2. **Respect all declared schemas** when sending or parsing requests.
3. **Communicate through MCP**â€”never make ad-hoc calls outside defined tool interfaces.
4. **Propagate correlation IDs** for traceability.
5. **Handle partial failures gracefully** and attempt safe retries where possible.
6. **Do not persist raw audio or private user data** unless explicitly authorized by policy.
7. **Log and summarize actions** for inclusion in the orchestratorâ€™s reasoning context.

---

## 13. Example Tool Ecosystem

| Tool Namespace | Description                     | Host Service          |
| -------------- | ------------------------------- | --------------------- |
| `discord.*`    | Join, leave, speak, send text   | Python Discord Bot        |
| `stt.*`        | Transcribe, diarize             | Python faster-whisper |
| `tts.*`        | Generate or stream speech audio | Python TTS            |
| `fs.*`         | File read/write/edit            | FS Service            |
| `git.*`        | Commit, push, branch, PR        | Git Service           |
| `http.*`       | Safe REST/API requests          | HTTP Proxy Service    |

All must conform to MCPâ€™s discovery and invocation format.

---

## 14. Scalability Model

| Layer              | Scaling Strategy                                        |
| ------------------ | ------------------------------------------------------- |
| Discord Bot        | One instance per Discord voice shard.                   |
| STT                | Stateless workers behind a load balancer.               |
| Orchestrator       | Multiple reasoning agents sharing a manifest and cache. |
| Additional Capability Servers | Independently scaled and auto-registered.               |

---

## 15. Summary

This system is a **distributed, voice-interactive AI framework** composed of interoperable services connected through the **Model Context Protocol (MCP)**.

It enables:

* Real-time, wake-word-driven speech interaction
* Accurate local transcription (faster-whisper)
* Structured reasoning and planning (llama.cpp)
* Declarative, manifest-based discovery of tools and capabilities
* Secure, auditable, and extensible orchestration

Your role as an **AI Agent** is to:

* Operate within these boundaries,
* Use the manifest for discovery,
* Communicate through MCP using structured requests, and
* Collaborate with other agents and services to fulfill user intent efficiently and safely.
