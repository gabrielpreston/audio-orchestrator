# Project Roadmap

## AI Development Agent â€” 2-Week Strategic Roadmap

**Goal:**  
Transition from an experimental voice-enabled Discord bot into the foundation
of a **Cursor-centric AI development agent** â€” one capable of understanding
spoken commands, iterating on ideas, writing and testing code, and driving the
software delivery lifecycle (SDLC) end-to-end.  
Discord (or similar platforms) become optional interfaces; the core systemâ€™s
value is its ability to act as a **hands-on, voice-driven collaborator inside
the development environment itself.**

---

## 1. Strategic Vision

Build an AI agent that:

- ğŸ§  **Understands context deeply** â€” not just natural language, but project structure, architecture, and constraints.
- ğŸ› ï¸ **Writes, tests, builds, and ships code autonomously** â€” able to operate as a â€œpair programmer++â€ that closes loops without needing manual follow-up.
- ğŸ™ï¸ **Takes spoken direction** â€” letting developers guide work conversationally while staying in flow.
- ğŸ”„ **Integrates seamlessly with the developer toolchain** â€” particularly Cursor, Git, build pipelines, and test harnesses.
- ğŸš€ **Improves over time** â€” learning from past decisions, style guides, and review feedback.

---

## 2. 14-Day Roadmap (Strategic Focus)

### Current status (codebase)

- âœ… STT service available (`services/stt/app.py`) and configured via `STT_BASE_URL`.
- âœ… Audio pipeline / Opus decode / POST to STT (`services/discord/audio.py`, `services/discord/transcription.py`).
- âœ… Discord integration and resolver wired (`services/discord/discord_voice.py`, `services/discord/main.py`).
- âœ… Centralized logging helpers (`services/common/logging.py`).
- âœ… Docker helpers (`Makefile`): `run`, `logs`, `docker-build`.

Additional implemented pieces discovered in the codebase:

- âœ… Allow-listing of users via `AUDIO_ALLOWLIST` (`services/discord/config.py`, `services/discord/audio.py`).
- âœ… Wake phrase configuration and filtering (`services/discord/wake.py`, `services/discord/config.py`).
- âœ… Transcript aggregation with retry/backoff when calling STT (`services/discord/transcription.py`).
- âœ… Structured MCP manifest loading for downstream tools (`services/discord/mcp.py`).

### Phase 1 â€” Stabilize the Core Voice Layer (Days 1-3)

Objective: Finalize the base voice ingestion pipeline so the agent can reliably hear and understand instructions.

- âœ… Voice input pipeline â€” Finalize PCM â†’ STT â†’ text pipeline, ensuring stable transcription from microphone or Discord. (Agent reliably receives commands in text form.)
- âœ… Command framing â€” Define a lightweight schema for â€œintent parsingâ€ (e.g., `action: create_file`, `action: run_tests`). (Voice commands map to actionable tasks.)
- â¬œ Optional: Multi-channel input â€” Support local mic input *and* Discord voice input with identical downstream handling. (Voice source becomes interchangeable.)

---

### Phase 2 â€” Cursor Environment Integration (Days 4-7)

Objective: Establish two-way communication between the voice agent and Cursorâ€™s API / local environment.

- â¬œ Cursor context access â€” Implement connection to Cursor API / local workspace to read project files, structure, and open buffers. (Agent can â€œseeâ€ the project and reason about it.)
- â¬œ Codegen orchestration â€” Define how agent proposals (from LLM) are written into files or suggested as diffs. (AI can write code directly into the repo.)
- âœ… Action verification layer â€” Implement test harness commands: e.g., â€œrun unit testsâ€, â€œcheck for linter errorsâ€. (Infrastructure present: `Makefile` targets `run`, `logs`.)

---

### Phase 3 â€” Voice-Driven Dev Flows (Days 8-11)

Objective: Prototype meaningful real-world use cases driven entirely by voice.

- â¬œ Voice-to-feature workflow â€” Example: â€œAdd a new `/healthz` endpointâ€ â†’ design, generate code, run tests, commit. (End-to-end task completion by voice.)
- â¬œ Task chaining â€” Allow multi-step workflows (e.g., â€œrefactor this service and write tests for itâ€). (Agent executes chained commands without micromanagement.)
- â¬œ Feedback refinement loop â€” Add conversational refinement (â€œmake that function genericâ€, â€œtry a different error strategyâ€). (Voice iteration feels natural and productive.)

---

### Phase 4 â€” Developer Workflow Integration (Days 12-14)

Objective: Tighten the feedback loop so the agent operates as a â€œteam memberâ€ inside the SDLC.

- â¬œ Git integration â€” Voice-triggered git actions (branch creation, commits, PR prep). (Agent contributes changes like a human developer.)
- â¬œ Build + deploy hooks â€” Voice commands trigger builds, CI runs, and deployment workflows. (AI can close the loop and ship code.)
- â¬œ Onboarding doc + demo â€” Document current capabilities, limitations, and roadmap to next iteration. (Ready for next contributors or productization phase.)

---

## 3. Guiding Principles

- **Cursor as the â€œoperating systemâ€:** The IDE is the primary surface where AI acts. Voice input is just one modality.
- **Voice is command, not gimmick:** Voice should translate to *intent* â€” â€œgenerateâ€, â€œtestâ€, â€œrefactorâ€ â€” not just text input.
- **Autonomy over assistance:** Aim for the agent to complete tasks end-to-end without manual hand-offs.
- **LLM as orchestrator, not executor:** LLM plans and reasons; deterministic code and tools actually execute.
- **Safety and reviewability:** All AI actions should be inspectable and reversible. Every change should go through version control.

---

## 4. Stretch Goals (Beyond 2 Weeks)

- ğŸ¤ Team-aware collaboration: Allow the agent to join standups, write summaries, or propose tickets.  
- ğŸ§  Persistent memory: Track architectural decisions and coding style over time.  
- ğŸŒ Multi-agent workflows: Split tasks into â€œplannerâ€, â€œcoderâ€, â€œreviewerâ€, and â€œdeployerâ€ personas.  
- ğŸ—£ï¸ Natural dialogue understanding: Handle ambiguous or incomplete instructions through clarifying questions.

---

## 5. Definition of Success

By the end of this 2-week sprint:

- The agent can **accept a spoken request**, **plan a solution**, **generate code**, **test it**, and **commit it** â€” all without leaving Cursor.
- The integration is **stable, modular, and extensible** enough to evolve into a full autonomous SDLC agent.
- There is enough documentation and architectural clarity for new contributors (or future you) to build on top confidently.

---
